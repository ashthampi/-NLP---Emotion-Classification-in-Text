# -NLP---Emotion-Classification-in-Text
Formative Assessment
<img width="640" alt="image" src="https://github.com/user-attachments/assets/4946aa42-42fc-4264-8c24-265e512bc08a">
<img width="649" alt="image" src="https://github.com/user-attachments/assets/49d327e9-3f9f-4857-87a7-53f7dd0a8f7b">
<img width="638" alt="image" src="https://github.com/user-attachments/assets/6eb25238-63c0-415e-86c9-9f664162c347">

Highlights:

Loading and Preprocessing: Text is cleaned using simple steps such as lowercase and removing unwanted characters.

Feature Extraction: Converted text into numerical values which represents the importance of words in each document.

Model Development: divided the dataset into training and testing parts,  models evaluated on unseen data.

Model Comparison: Used 2 different models: Naive Bayes and SVM,(text-based classification) and (powerful for complex patterns).

Performance: Accuracy (checking predictions are correct) and F1-score (precision and recall) to model performance comparison.
 
 Summary:
 
1. Naive Bayes:
it is a simple and fast model, assumes that each word in a comment is independent of others. It's great for text classification, easy to use, and works well with smaller datasets.
Performance:
Accuracy: predicts emotions correctly.
F1-Score: It balances well between predicting emotions correctly and not missing important ones.

Support Vector Machine (SVM):
powerful model that can separate emotions using the best boundary between them. Handles complex patterns, is flexible, captures subtle differences between emotions.
Performance:
Accuracy: predicts emotions very accurately.
F1-Score: balances precision and recall.
